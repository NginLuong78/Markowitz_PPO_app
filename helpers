"""
helpers_vn30.py
---------------------------------------
Module hỗ trợ xử lý dữ liệu, tính toán chỉ báo kỹ thuật,
tối ưu hóa danh mục Markowitz, và xây dựng môi trường giao dịch VN30.
---------------------------------------
Tác giả: Thành Công Nguyễn (2025)
"""

import os
import io
import math
import time
import json
import logging
import warnings
from typing import List, Tuple, Dict, Optional, Any
from datetime import datetime

import numpy as np
import pandas as pd
from scipy.optimize import minimize
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import streamlit as st

warnings.filterwarnings("ignore")
logging.getLogger("matplotlib").setLevel(logging.WARNING)

# ======================
# 1️⃣ Kỹ thuật chỉ báo
# ======================

def compute_rsi(series: pd.Series, period: int = 14) -> pd.Series:
    """Tính chỉ báo RSI (Relative Strength Index)."""
    delta = series.diff()
    gain = delta.where(delta > 0, 0.0)
    loss = -delta.where(delta < 0, 0.0)
    avg_gain = gain.rolling(window=period, min_periods=1).mean()
    avg_loss = loss.rolling(window=period, min_periods=1).mean()
    rs = avg_gain / (avg_loss + 1e-10)
    rsi = 100 - (100 / (1 + rs))
    return rsi.fillna(50.0)

def compute_bollinger_bands(series: pd.Series, window: int = 20, num_std: float = 2.0):
    """Tính Bollinger Bands."""
    ma = series.rolling(window=window, min_periods=1).mean()
    std = series.rolling(window=window, min_periods=1).std()
    upper = ma + num_std * std
    lower = ma - num_std * std
    return ma, upper, lower

def compute_ema(series: pd.Series, span: int = 20) -> pd.Series:
    """Exponential Moving Average (EMA)."""
    return series.ewm(span=span, adjust=False).mean().fillna(method="bfill")

def compute_macd(series: pd.Series, short: int = 12, long: int = 26, signal: int = 9):
    """Tính MACD."""
    ema_short = compute_ema(series, short)
    ema_long = compute_ema(series, long)
    macd = ema_short - ema_long
    signal_line = macd.ewm(span=signal, adjust=False).mean()
    return macd, signal_line

def compute_atr(high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):
    """Tính ATR (Average True Range)."""
    tr = pd.concat([
        high - low,
        (high - close.shift()).abs(),
        (low - close.shift()).abs()
    ], axis=1).max(axis=1)
    atr = tr.rolling(window=period, min_periods=1).mean()
    return atr.fillna(method="bfill")

def compute_obv(close: pd.Series, volume: pd.Series) -> pd.Series:
    """Tính On-Balance Volume (OBV)."""
    obv = [0.0]
    for i in range(1, len(close)):
        if close[i] > close[i - 1]:
            obv.append(obv[-1] + volume[i])
        elif close[i] < close[i - 1]:
            obv.append(obv[-1] - volume[i])
        else:
            obv.append(obv[-1])
    return pd.Series(obv, index=close.index).fillna(method="ffill").fillna(0.0)

def compute_volume_oscillator(volume: pd.Series, short: int = 5, long: int = 20):
    """Tính Volume Oscillator (%)."""
    short_ma = volume.rolling(window=short, min_periods=1).mean()
    long_ma = volume.rolling(window=long, min_periods=1).mean().replace(0, 1e-10)
    return ((short_ma - long_ma) / (long_ma + 1e-10) * 100).fillna(0.0)


# ===============================
# 2️⃣ VN30 Index + Daily Data
# ===============================

def compute_vn30_index_with_indicators(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Tính toán chỉ báo kỹ thuật cho VN30 Index."""
    df = df.sort_values("date").reset_index(drop=True)
    df["SMA_20"] = df["close"].rolling(window=20, min_periods=1).mean()
    df["EMA_20"] = compute_ema(df["close"], 20)
    df["RSI_14"] = compute_rsi(df["close"], 14)
    df["MACD"], df["MACD_signal"] = compute_macd(df["close"])
    df["ATR_14"] = compute_atr(df["high"], df["low"], df["close"])
    df["OBV"] = compute_obv(df["close"], df["volume"])
    df["Vol_Osc"] = compute_volume_oscillator(df["volume"])

    daily_df = df[["date", "close", "RSI_14", "ATR_14", "MACD", "MACD_signal", "Vol_Osc"]].copy()
    df = df.fillna(method='ffill').fillna(method='bfill')
    daily_df = daily_df.fillna(method='ffill').fillna(method='bfill')
    return df, daily_df


def plot_vn30_index_indicators(df: pd.DataFrame):
    """Biểu đồ VN30 với RSI và Bollinger Bands."""
    fig, ax1 = plt.subplots(figsize=(12, 6))
    ax1.plot(df["date"], df["close"], label="VN30 Close", color="blue")
    ma, upper, lower = compute_bollinger_bands(df["close"])
    ax1.plot(df["date"], ma, color="orange", label="SMA20")
    ax1.fill_between(df["date"], lower, upper, color="gray", alpha=0.2, label="Bollinger Band")
    ax1.set_xlabel("Date")
    ax1.set_ylabel("Price")
    ax1.legend(loc="upper left")
    ax1.grid(True)
    plt.tight_layout()
    st.pyplot(fig)


# ===============================
# 3️⃣ Tối ưu Markowitz
# ===============================

def calculate_annualized_returns(df: pd.DataFrame, annualize: bool = True):
    """Tính toán lợi suất trung bình năm."""
    df["log_return"] = np.log(df["close"] / df["close"].shift(1))
    mean_return = df.groupby("id")["log_return"].mean().dropna()
    if annualize:
        mean_return *= 252
    return mean_return

def calculate_cov_matrix(df: pd.DataFrame, annualize: bool = True):
    """Tính ma trận hiệp phương sai."""
    pivot = df.pivot(index="date", columns="id", values="close").dropna(how="all", axis=1)
    returns = np.log(pivot / pivot.shift(1)).dropna(how="all", axis=0)
    cov_matrix = returns.cov().fillna(0.0)
    if annualize:
        cov_matrix *= 252
    return cov_matrix

def optimize_markowitz(mean_returns, cov_matrix, top_n=10, method='sharpe', lambda_l2=0.01, max_weight=0.3):
    """Tối ưu danh mục Markowitz."""
    ids = list(mean_returns.index)
    mean_returns = mean_returns.values
    cov_matrix = cov_matrix.values
    num_assets = len(ids)

    def objective(weights):
        weights = np.clip(weights, 0, 1)
        port_return = np.dot(weights, mean_returns)
        port_vol = np.sqrt(weights.T @ cov_matrix @ weights)
        if method == "variance":
            return port_vol + lambda_l2 * np.sum(weights ** 2)
        else:
            sharpe = -port_return / (port_vol + 1e-8)
            return sharpe + lambda_l2 * np.sum(weights ** 2)

    constraints = [{"type": "eq", "fun": lambda w: np.sum(w) - 1}]
    bounds = tuple((0, max_weight) for _ in range(num_assets))
    x0 = np.ones(num_assets) / num_assets

    res = minimize(objective, x0=x0, bounds=bounds, constraints=constraints, method="SLSQP")
    weights = np.clip(res.x, 0, 1)
    weights /= np.sum(weights)
    sorted_idx = np.argsort(-weights)[:top_n]
    selected_ids = [ids[i] for i in sorted_idx]
    selected_weights = weights[sorted_idx]
    return selected_ids, selected_weights, weights


def plot_efficient_frontier(mean_returns, cov_matrix, num_portfolios=3000):
    """Vẽ đường Efficient Frontier."""
    np.random.seed(42)
    port_returns, port_vols = [], []
    for _ in range(num_portfolios):
        w = np.random.random(len(mean_returns))
        w /= np.sum(w)
        port_returns.append(np.dot(w, mean_returns))
        port_vols.append(np.sqrt(w.T @ cov_matrix @ w))
    port_returns, port_vols = np.array(port_returns), np.array(port_vols)
    plt.figure(figsize=(8, 5))
    plt.scatter(port_vols, port_returns, s=8, alpha=0.4)
    plt.xlabel("Volatility")
    plt.ylabel("Return")
    plt.title("Efficient Frontier")
    st.pyplot(plt)


# ===============================
# 4️⃣ Môi trường VN30TradingEnv
# ===============================

import gymnasium as gym
from gymnasium import spaces

class VN30TradingEnv(gym.Env):
    """
    Môi trường Giao dịch VN30 mô phỏng quá trình tối ưu danh mục bằng PPO hoặc Markowitz.
    """

    metadata = {"render.modes": ["human"]}

    def __init__(self, df: pd.DataFrame, tickers: List[str], window_size: int = 30, transaction_cost: float = 0.001):
        super().__init__()
        self.df = df
        self.tickers = tickers
        self.num_assets = len(tickers)
        self.window_size = window_size
        self.transaction_cost = transaction_cost

        self.action_space = spaces.Box(low=0.0, high=1.0, shape=(self.num_assets,), dtype=np.float32)
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_assets, window_size, 6), dtype=np.float32)

        self.reset(seed=42)

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.current_step = self.window_size
        self.cash = 1_000_000_000.0
        self.asset_balance = np.zeros(self.num_assets)
        self.portfolio_value = self.cash
        self.navs = [self.cash]
        self.total_fees = 0.0
        self.dates = sorted(self.df["date"].unique())
        self.asset_data = {t: self.df[self.df["id"] == t].reset_index(drop=True) for t in self.tickers}
        return self._get_observation(), {}

    def _get_observation(self):
        obs = []
        for t in self.tickers:
            data = self.asset_data[t]
            slice_data = data.iloc[max(0, self.current_step - self.window_size):self.current_step]
            obs.append(slice_data[["close", "RSI", "ATR", "MACD", "MACD_signal", "Vol_Osc"]].values)
        obs = np.array(obs)
        if obs.shape[1] < self.window_size:
            pad = np.zeros((self.num_assets, self.window_size - obs.shape[1], 6))
            obs = np.concatenate([pad, obs], axis=1)
        return obs

    def step(self, action):
        action = np.clip(action, 0, 1)
        weights = action / (np.sum(action) + 1e-8)

        prices = self._get_prices(self.current_step)
        prev_value = self.get_portfolio_value()
        self._update_portfolio(weights, prices)

        current_value = self.get_portfolio_value()
        reward = (current_value - prev_value) / prev_value

        self.navs.append(current_value)
        self.current_step += 1
        terminated = self.current_step >= len(self.dates) - 1
        info = {"portfolio_value": current_value, "sharpe": self.get_sharpe_ratio()}
        return self._get_observation(), float(reward), terminated, False, info

    def _get_prices(self, idx: int) -> np.ndarray:
        prices = []
        for ticker in self.tickers:
            data = self.asset_data[ticker]
            if idx >= len(data):
                prices.append(data["close"].iloc[-1])
            else:
                prices.append(data["close"].iloc[idx])
        return np.array(prices, dtype=np.float32)

    def _update_portfolio(self, weights: np.ndarray, prices: np.ndarray):
        total_value = self.cash + np.sum(self.asset_balance * prices)
        target_value = total_value * weights
        current_value = self.asset_balance * prices
        trade_value = target_value - current_value

        fees = np.sum(np.abs(trade_value)) * self.transaction_cost
        self.total_fees += fees
        self.cash -= fees
        self.asset_balance = target_value / (prices + 1e-8)
        self.cash = total_value - np.sum(self.asset_balance * prices) - fees
        self.portfolio_value = self.cash + np.sum(self.asset_balance * prices)

    def get_portfolio_value(self) -> float:
        idx = min(self.current_step, len(self.dates) - 1)
        prices = self._get_prices(idx)
        return self.cash + np.sum(self.asset_balance * prices)

    def get_sharpe_ratio(self) -> float:
        if len(self.navs) < 2:
            return 0.0
        returns = np.diff(self.navs) / np.array(self.navs[:-1])
        return np.mean(returns) / (np.std(returns) + 1e-8)

    def get_max_drawdown(self) -> float:
        if not self.navs:
            return 0.0
        nav_series = np.array(self.navs)
        rolling_max = np.maximum.accumulate(nav_series)
        drawdown = (nav_series - rolling_max) / (rolling_max + 1e-8)
        return np.min(drawdown)

    def render(self, mode="human"):
        df_nav = pd.DataFrame({"Date": self.dates[self.window_size:self.window_size + len(self.navs)],
                               "NAV": self.navs})
        sharpe = self.get_sharpe_ratio()
        mdd = self.get_max_drawdown()
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.plot(df_nav["Date"], df_nav["NAV"], label="NAV", color="blue")
        ax.set_title(f"Portfolio NAV | Sharpe: {sharpe:.2f} | Max Drawdown: {mdd:.2%}")
        ax.set_xlabel("Date")
        ax.set_ylabel("Portfolio Value (VND)")
        ax.legend()
        ax.grid(True)
        plt.tight_layout()
        st.pyplot(fig)

# This combined file contains two standalone scripts for your project:
# 1) train_ppo_vn30.py  - training script to train PPO on VN30TradingEnv
# 2) evaluate_model.py  - evaluation script to load a trained PPO model and produce metrics/plots
#
# Save each section into its own file if you prefer (separate by the '### FILE:' markers).

"""
### FILE: train_ppo_vn30.py
Train PPO on VN30TradingEnv (uses helpers_vn30.py)
Usage example:
    python train_ppo_vn30.py --csv vn30_30stocks.csv --save_dir ./checkpoints --timesteps 50000 --log_interval 10
"""

import os
import argparse
import logging
from typing import Callable

import numpy as np
import pandas as pd

# local helpers (make sure helpers_vn30.py is on PYTHONPATH or same folder)
import helpers_vn30 as helpers

# stable-baselines3 imports guarded
try:
    import torch
    from stable_baselines3 import PPO
    from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor, VecNormalize
    from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback, CallbackList, BaseCallback
    from stable_baselines3.common.monitor import Monitor
    STABLE_AVAILABLE = True
except Exception as e:
    STABLE_AVAILABLE = False


class TensorboardEntropyCallback(BaseCallback):
    """Callback to log entropy coefficient to tensorboard (if available)."""
    def __init__(self, verbose=0):
        super().__init__(verbose)

    def _on_step(self) -> bool:
        if self.logger:
            ent = getattr(self.model, 'ent_coef', None)
            if hasattr(ent, 'item'):
                try:
                    ent_val = ent.item()
                except Exception:
                    ent_val = float(ent)
            else:
                ent_val = float(ent) if ent is not None else None
            if ent_val is not None:
                self.logger.record('train/entropy_coef', ent_val)
        return True


def create_vec_env(env_fn: Callable):
    """Create normalized vectorized environment for training and evaluation."""
    v = DummyVecEnv([env_fn])
    v = VecMonitor(v)
    v = VecNormalize(v, norm_obs=True, norm_reward=False, clip_obs=10.0)
    return v


def make_env_factory(df: pd.DataFrame, tickers: list, window_size: int = 10, transaction_cost: float = 0.001):
    def _init():
        env = helpers.VN30TradingEnv(df=df, tickers=tickers, window_size=window_size, transaction_cost=transaction_cost)
        env = Monitor(env)
        return env
    return _init


def train(csv_path: str, save_dir: str = './checkpoints', total_timesteps: int = 50000, window_size: int = 10):
    if not STABLE_AVAILABLE:
        raise RuntimeError('stable-baselines3 or torch not available. Install with: pip install stable-baselines3 torch')

    os.makedirs(save_dir, exist_ok=True)
    df_raw = pd.read_csv(csv_path)
    # normalize columns
    df_raw.columns = df_raw.columns.str.lower()
    required = {'date', 'id', 'open', 'high', 'low', 'close', 'volume'}
    if not required.issubset(set(df_raw.columns)):
        raise KeyError(f'CSV must contain columns: {sorted(required)}')

    # compute indicators per stock
    df_with_indicators = helpers.add_indicators_per_stock(df_raw)
    # choose tickers
    tickers = sorted([t for t in df_with_indicators['id'].unique()])

    # prepare env factories
    env_fn = make_env_factory(df_with_indicators, tickers, window_size=window_size)
    eval_env_fn = make_env_factory(df_with_indicators, tickers, window_size=window_size)

    vec_env = create_vec_env(env_fn)
    vec_eval = create_vec_env(eval_env_fn)
    vec_eval.training = False

    # callbacks
    checkpoint_cb = CheckpointCallback(save_freq=max(1, total_timesteps // 5), save_path=save_dir, name_prefix='ppo_vn30')
    eval_cb = EvalCallback(vec_eval, best_model_save_path=save_dir, log_path=save_dir, eval_freq=max(1, total_timesteps // 10), deterministic=True, render=False)
    ent_cb = TensorboardEntropyCallback()
    cb_list = CallbackList([checkpoint_cb, eval_cb, ent_cb])

    # PPO hyperparameters: conservative defaults that work on CPU
    model = PPO('MlpPolicy', vec_env, verbose=1,
                tensorboard_log=os.path.join(save_dir, 'tensorboard'),
                n_steps=2048, batch_size=64, n_epochs=10,
                learning_rate=3e-4, gae_lambda=0.95, gamma=0.99, ent_coef=0.005,
                max_grad_norm=0.5, clip_range=0.2)

    try:
        model.learn(total_timesteps=int(total_timesteps), callback=cb_list)
        model_path = os.path.join(save_dir, 'ppo_vn30.zip')
        model.save(model_path)
        print(f'Training finished. Model saved to: {model_path}')
        return model_path
    except Exception as e:
        model.save(os.path.join(save_dir, 'ppo_vn30_failed.zip'))
        raise


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Train PPO on VN30TradingEnv')
    parser.add_argument('--csv', type=str, required=True, help='Path to CSV containing stock data')
    parser.add_argument('--save_dir', type=str, default='./checkpoints', help='Directory to save models and logs')
    parser.add_argument('--timesteps', type=int, default=50000, help='Total timesteps for PPO.learn')
    parser.add_argument('--window', type=int, default=10, help='Window size for env')
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO)
    train(args.csv, save_dir=args.save_dir, total_timesteps=args.timesteps, window_size=args.window)


# ------------------------------------------------------------------------------
#
# ### FILE: evaluate_model.py
# Load trained PPO model, run evaluation episodes, compute metrics and plots
# Usage example:
#    python evaluate_model.py --model ./checkpoints/ppo_vn30.zip --csv vn30_30stocks.csv --episodes 1 --window 10 --out_dir ./eval
#
# ------------------------------------------------------------------------------

import os
import argparse
import json
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

try:
    import torch
    from stable_baselines3 import PPO
    STABLE_AVAILABLE = True
except Exception:
    STABLE_AVAILABLE = False

import helpers_vn30 as helpers


def run_episode(env, model, render=False, deterministic=True, max_steps=None):
    obs, info = env.reset()
    done = False
    navs = [env.get_portfolio_value()]
    rewards = []
    actions = []
    steps = 0
    while not done:
        action, _ = model.predict(obs, deterministic=deterministic)
        obs, reward, done, truncated, info = env.step(action)
        navs.append(env.get_portfolio_value())
        rewards.append(reward)
        actions.append(action)
        steps += 1
        if max_steps is not None and steps >= max_steps:
            break
    return np.array(navs), np.array(rewards), np.array(actions), info


def compute_metrics_from_navs(navs: np.ndarray):
    # basic metrics: total return, CAGR, volatility, sharpe, max drawdown, sortino
    total_return = navs[-1] / navs[0] - 1.0
    days = len(navs)
    years = max(days / 252.0, 1.0 / 252.0)
    cagr = (navs[-1] / navs[0]) ** (1.0 / years) - 1.0
    returns = np.diff(navs) / (navs[:-1] + 1e-10)
    ann_vol = np.std(returns) * math.sqrt(252) if len(returns) > 1 else 0.0
    sharpe = (np.mean(returns) / (np.std(returns) + 1e-10)) * math.sqrt(252) if len(returns) > 1 else 0.0
    neg = returns[returns < 0]
    downside = np.std(neg) * math.sqrt(252) if len(neg) > 0 else 1e-10
    sortino = (np.mean(returns) / downside) if downside > 0 else np.nan
    # drawdown
    running_max = np.maximum.accumulate(navs)
    drawdowns = (navs - running_max) / (running_max + 1e-10)
    max_dd = np.min(drawdowns)
    return {
        'total_return': total_return,
        'cagr': cagr,
        'ann_vol': ann_vol,
        'sharpe': sharpe,
        'sortino': sortino,
        'max_drawdown': max_dd
    }


def evaluate_model(model_path: str, csv_path: str, out_dir: str = './eval', episodes: int = 1, window: int = 10):
    if not STABLE_AVAILABLE:
        raise RuntimeError('stable-baselines3 not available. Install to run evaluation with PPO model.')

    os.makedirs(out_dir, exist_ok=True)
    df_raw = pd.read_csv(csv_path)
    df_raw.columns = df_raw.columns.str.lower()
    df_with_indicators = helpers.add_indicators_per_stock(df_raw)
    tickers = sorted(list(df_with_indicators['id'].unique()))

    # load model
    model = PPO.load(model_path)

    # create env
    def env_fn():
        env = helpers.VN30TradingEnv(df_with_indicators, tickers, window_size=window)
        return env

    env = env_fn()

    results = []
    for ep in range(episodes):
        navs, rewards, actions, info = run_episode(env, model, deterministic=True)
        metrics = compute_metrics_from_navs(navs)
        metrics['episode'] = ep + 1
        metrics['steps'] = len(navs) - 1
        results.append(metrics)

        # save navs and rewards
        np.savetxt(os.path.join(out_dir, f'navs_ep{ep+1}.csv'), navs, delimiter=',')
        np.savetxt(os.path.join(out_dir, f'rewards_ep{ep+1}.csv'), rewards, delimiter=',')

        # plot NAV
        plt.figure(figsize=(10,5))
        plt.plot(navs)
        plt.title(f'NAV — Episode {ep+1} | Return: {metrics["total_return"]:.2%} | Sharpe: {metrics["sharpe"]:.2f}')
        plt.xlabel('Step'); plt.ylabel('NAV')
        plt.grid(True)
        plt.tight_layout()
        plt.savefig(os.path.join(out_dir, f'nav_ep{ep+1}.png'))
        plt.close()

    df_res = pd.DataFrame(results)
    df_res.to_csv(os.path.join(out_dir, 'evaluation_summary.csv'), index=False)
    print('Evaluation complete. Results saved to', out_dir)
    return df_res


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Evaluate PPO model on VN30TradingEnv')
    parser.add_argument('--model', type=str, required=True, help='Path to trained PPO model (.zip)')
    parser.add_argument('--csv', type=str, required=True, help='CSV with historical data')
    parser.add_argument('--episodes', type=int, default=1)
    parser.add_argument('--window', type=int, default=10)
    parser.add_argument('--out_dir', type=str, default='./eval')
    args = parser.parse_args()

    evaluate_model(args.model, args.csv, out_dir=args.out_dir, episodes=args.episodes, window=args.window)

